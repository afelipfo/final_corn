# MobileNetV3Large Inference Pipeline

Sistema de inferencia optimizado para detecci√≥n de enfermedades del ma√≠z usando exclusivamente MobileNetV3Large en dispositivos edge.

## Contenido del Directorio

- `run_pipeline.py`: **Script principal para ejecuci√≥n autom√°tica completa (recomendado)**
- `config.yaml`: Configuraci√≥n completa de hiperpar√°metros para MobileNetV3Large
- `convert_to_tflite.py`: Conversi√≥n del modelo a formato TensorFlow Lite con optimizaciones
- `validate_model.py`: Validaci√≥n completa incluyendo accuracy y matriz de confusi√≥n
- `inference.py`: Pipeline de inferencia optimizado para producci√≥n

## Ejecuci√≥n en Google Colab (Recomendado)

### Preparaci√≥n Inicial en Colab

```python
# 1. Instalar todas las dependencias necesarias
!pip install tensorflow tensorflow-model-optimization pyyaml scikit-learn pillow matplotlib seaborn

# 2. üîÑ REINICIAR RUNTIME AQU√ç (Runtime ‚Üí Restart runtime)
# Esto es necesario por conflictos de numpy despu√©s de instalar tensorflow-model-optimization

# 3. Obtener la versi√≥n M√ÅS RECIENTE del repositorio (fuerza actualizaci√≥n)
!rm -rf corn-diseases-detection  # Eliminar versi√≥n anterior si existe
!git clone https://github.com/ojgonzalezz/corn-diseases-detection.git
!cd corn-diseases-detection && git log --oneline -1  # Verificar versi√≥n

# 4. Montar Google Drive para acceder a los datos
from google.colab import drive
drive.mount('/content/drive')
```

### Opci√≥n Alternativa (si quieres preservar archivos locales):

```python
# Si tienes archivos locales que quieres preservar, usa esta opci√≥n:
!pip install tensorflow tensorflow-model-optimization pyyaml scikit-learn pillow matplotlib seaborn

# üîÑ REINICIAR RUNTIME AQU√ç (Runtime ‚Üí Restart runtime)
# Necesario por conflictos de numpy

# Forzar actualizaci√≥n completa del repositorio
!cd corn-diseases-detection && git fetch origin && git reset --hard origin/main
!cd corn-diseases-detection && git log --oneline -1  # Verificar versi√≥n actualizada

from google.colab import drive
drive.mount('/content/drive')
```

### Ejecuci√≥n Autom√°tica Completa

```bash
# Ejecutar todo el pipeline autom√°ticamente con tus datos en Drive
!cd corn-diseases-detection/mobilenetv3_inference && python run_pipeline.py --data-path /content/drive/MyDrive/corn-diseases-data
```

**Qu√© hace autom√°ticamente:**
1. **Conversi√≥n**: Crea modelo MobileNetV3Large optimizado en TensorFlow Lite
2. **Validaci√≥n**: Eval√∫a el modelo con datos de test y genera accuracy + matriz de confusi√≥n
3. **Inferencia**: Ejecuta demo de inferencia con m√∫ltiples muestras
4. **Reportes**: Genera archivos JSON con m√©tricas y gr√°ficos de resultados

**Archivos generados:**
- `models/mobilenetv3_large_optimized.tflite`: Modelo optimizado
- `results/validation_report.json`: Accuracy y m√©tricas completas
- `results/confusion_matrix.png`: Matriz de confusi√≥n visual
- `results/inference_demo.json`: Resultados de inferencia

### Par√°metros del Script Autom√°tico

```bash
python run_pipeline.py [opciones]

Opciones:
  --config CONFIG           Archivo de configuraci√≥n (default: config.yaml)
  --data-path DATA_PATH     Ruta a los datos (default: ../data)
  --max-samples MAX_SAMPLES M√°ximo muestras para validaci√≥n (default: 500)
  --inference-samples SAMPLES Muestras para demo de inferencia (default: 20)
```

### Ejemplos de Uso Personalizado

```bash
# M√°s muestras para validaci√≥n m√°s precisa
!cd corn-diseases-detection/mobilenetv3_inference && python run_pipeline.py --data-path /content/drive/MyDrive/corn-diseases-data --max-samples 1000

# Menos muestras para demo r√°pida
!cd corn-diseases-detection/mobilenetv3_inference && python run_pipeline.py --data-path /content/drive/MyDrive/corn-diseases-data --inference-samples 10
```

## Requisitos del Sistema

- **Python**: 3.8+
- **TensorFlow**: 2.10+
- **GPU**: Recomendado para conversi√≥n del modelo
- **Memoria RAM**: M√≠nimo 8GB
- **Espacio en disco**: 2GB libres

## Instalaci√≥n

```bash
# Instalar dependencias
pip install tensorflow tensorflow-model-optimization pyyaml scikit-learn pillow matplotlib seaborn

# Verificar instalaci√≥n
python -c "import tensorflow as tf; print(f'TensorFlow {tf.__version__}')"
```

## Arquitectura del Modelo

### MobileNetV3Large Configurado

```yaml
model:
  name: "MobileNetV3Large"
  input_shape: [224, 224, 3]
  alpha: 1.0
  minimalistic: false
  include_top: true
  weights: "imagenet"
```

### Caracter√≠sticas T√©cnicas

- **Activaci√≥n**: Hard-swish (h-swish)
- **Bloques SE**: Squeeze-and-Excitation con ratio 0.25
- **Estructura**: Inverted residual bottlenecks
- **Preprocesamiento**: Escala [-1, 1] espec√≠fica para MobileNetV3

## Optimizaciones Implementadas

### Poda (Pruning)

```yaml
pruning:
  enabled: false  # Temporalmente deshabilitado por dependencias
  schedule_type: "PolynomialDecay"
  initial_sparsity: 0.0
  final_sparsity: 0.5
  begin_step: 0
  end_step: 100
  frequency: 10
```

### Cuantizaci√≥n INT8

```yaml
quantization:
  enabled: true
  optimization: ["DEFAULT"]
  representative_dataset_samples: 100
  supported_ops: ["TFLITE_BUILTINS_INT8"]
```

### Configuraci√≥n de Inferencia

```yaml
inference:
  batch_size: 1
  num_threads: 1
  use_xnnpack_delegate: false
```

## Instalaci√≥n

```bash
# Instalar dependencias
pip install tensorflow tensorflow-model-optimization pyyaml scikit-learn pillow matplotlib seaborn
```

## Uso Manual (Avanzado)

Si necesitas ejecutar pasos individuales o personalizar el proceso:

### 1. Conversi√≥n a TensorFlow Lite

```bash
python convert_to_tflite.py \
    --config config.yaml \
    --output models/mobilenetv3_large_optimized.tflite \
    --data-path ../data/train
```

### 2. Validaci√≥n del Modelo

```bash
python validate_model.py \
    --config config.yaml \
    --model models/mobilenetv3_large_optimized.tflite \
    --test-data ../data/test \
    --max-samples 500 \
    --output results/validation_report.json
```

### 3. Inferencia

```bash
# Imagen individual
python inference.py \
    --config config.yaml \
    --model models/mobilenetv3_large_optimized.tflite \
    --image path/to/image.jpg

# Procesamiento por lotes
python inference.py \
    --config config.yaml \
    --model models/mobilenetv3_large_optimized.tflite \
    --batch \
    --num-samples 100
```

## Estructura de Datos Requerida

```
data/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ Blight/
‚îÇ   ‚îú‚îÄ‚îÄ Common_Rust/
‚îÇ   ‚îú‚îÄ‚îÄ Gray_Leaf_Spot/
‚îÇ   ‚îî‚îÄ‚îÄ Healthy/
‚îú‚îÄ‚îÄ val/
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ Blight/
    ‚îú‚îÄ‚îÄ Common_Rust/
    ‚îú‚îÄ‚îÄ Gray_Leaf_Spot/
    ‚îî‚îÄ‚îÄ Healthy/
```

## Clases de Enfermedades

- **Blight**: Mancha bacteriana
- **Common_Rust**: Roya com√∫n
- **Gray_Leaf_Spot**: Mancha gris de la hoja
- **Healthy**: Hojas sanas

## M√©tricas Esperadas

- **Accuracy**: ‚â•85% en conjunto de test
- **Tama√±o del modelo**: 5-7 MB (4-5x reducci√≥n)
- **Latencia**: <50ms por imagen en hardware edge
- **Uso de memoria**: <100MB durante inferencia

## Configuraci√≥n de Producci√≥n

### Hardware Soportado

- Raspberry Pi 4/5
- NVIDIA Jetson Nano/Xavier
- Dispositivos m√≥viles Android/iOS
- CPU multi-core con XNNPACK delegate

### Variables de Entorno

```bash
export TF_CPP_MIN_LOG_LEVEL=2  # Reducir logs de TensorFlow
export TF_ENABLE_ONEDNN_OPTS=1 # Optimizaciones adicionales
```

## Notas T√©cnicas

- El sistema est√° optimizado exclusivamente para MobileNetV3Large
- Los datos deben provenir √∫nicamente del directorio `/data`
- La cuantizaci√≥n requiere un conjunto representativo de al menos 100 muestras
- Los modelos generados son compatibles con TensorFlow Lite Interpreter
- Se recomienda GPU para la conversi√≥n y validaci√≥n inicial

## Soluci√≥n de Problemas

### Error de Memoria

```bash
# Reducir batch size en config.yaml
inference:
  batch_size: 1
  num_threads: 1
```

### Modelo no Carga

- Verificar que el archivo .tflite existe
- Comprobar compatibilidad de TensorFlow Lite
- Validar que el modelo fue convertido correctamente

### Baja Precisi√≥n

- Verificar calidad de datos de entrenamiento
- Ajustar par√°metros de cuantizaci√≥n si es necesario
- Considerar reentrenamiento con m√°s epochs

---

**Nota**: Para la mayor√≠a de los usuarios, se recomienda usar `python run_pipeline.py` para ejecutar todo autom√°ticamente en lugar de los scripts individuales.
