{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåΩ Entrenamiento MobileNetV3 - ARQUITECTURA ULTIMATE V2\n",
        "\n",
        "**Objetivo: >85% Accuracy + >80% Recall**\n",
        "\n",
        "## üéØ Cambios en V2:\n",
        "1. ‚úÖ **80 √©pocas** (aumentado de 60) para alcanzar 85%\n",
        "2. ‚úÖ **NO fine-tuning autom√°tico** (causaba colapso de 83.81% ‚Üí 58%)\n",
        "3. ‚úÖ Arquitectura 384‚Üí192 (probada y funcional)\n",
        "4. ‚úÖ Batch size 32 + Cosine Decay LR\n",
        "5. ‚ö†Ô∏è Fine-tuning SOLO SI ES ABSOLUTAMENTE NECESARIO (bloque separado)\n",
        "\n",
        "**Resultado V1:** 83.81% en √©poca 60 (solo falt√≥ 1.19%)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß BLOQUE 1: Setup y Verificaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1.2 Clonar repositorio\n",
        "!git clone -b main https://github.com/ojgonzalezz/corn-diseases-detection.git\n",
        "%cd corn-diseases-detection/entrenamiento_modelos\n",
        "\n",
        "# 1.3 Instalar dependencias\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# 1.4 Crear directorios necesarios en Drive\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/models\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/logs\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/mlruns\n",
        "\n",
        "print(\"\\n‚úÖ Setup completado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è BLOQUE 2: Configuraci√≥n OPTIMIZADA y Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Importar configuraci√≥n base\n",
        "from config import *\n",
        "from utils import setup_gpu\n",
        "\n",
        "# ==================== CONFIGURACI√ìN ULTIMATE V2 ====================\n",
        "BATCH_SIZE = 32  # Probado y funcional\n",
        "EPOCHS = 80  # Aumentado de 60 para alcanzar 85%\n",
        "LEARNING_RATE = 0.001  # LR inicial\n",
        "EARLY_STOPPING_PATIENCE = 25  # M√°s paciencia (80 √©pocas)\n",
        "\n",
        "# Configurar GPU\n",
        "setup_gpu(GPU_MEMORY_LIMIT)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"CONFIGURACI√ìN ULTIMATE V2\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"√âpocas: {EPOCHS} (aumentado de 60)\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE} (Cosine Decay)\")\n",
        "print(f\"Early Stopping Patience: {EARLY_STOPPING_PATIENCE}\")\n",
        "print(f\"Fine-tuning: DESHABILITADO (causaba colapso)\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear generadores de datos\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"Creando generadores de datos...\\n\")\n",
        "\n",
        "# Solo rescale (augmentation ya aplicado en preprocessing)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "test_gen = val_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(f\"üìä Dataset:\")\n",
        "print(f\"  Training:   {train_gen.samples} im√°genes ({train_gen.samples // BATCH_SIZE} batches)\")\n",
        "print(f\"  Validation: {val_gen.samples} im√°genes ({val_gen.samples // BATCH_SIZE} batches)\")\n",
        "print(f\"  Test:       {test_gen.samples} im√°genes ({test_gen.samples // BATCH_SIZE} batches)\")\n",
        "\n",
        "# Calcular class weights para maximizar recall\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_gen.classes),\n",
        "    y=train_gen.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(f\"\\n‚öñÔ∏è Class weights: {class_weight_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear modelo ULTIMATE V2\n",
        "def create_ultimate_v2_model(num_classes, image_size, initial_learning_rate, steps_per_epoch, total_epochs):\n",
        "    \"\"\"\n",
        "    Arquitectura ULTIMATE V2 - SIN fine-tuning autom√°tico\n",
        "    \n",
        "    Mejoras:\n",
        "    - Dense(384) ‚Üí Dense(192): Probada y funcional (83.81% en V1)\n",
        "    - Dropout(0.4, 0.35): Regularizaci√≥n √≥ptima\n",
        "    - Cosine Decay ajustado a 80 √©pocas\n",
        "    - NO fine-tuning (evita colapso catastr√≥fico)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Cargar base preentrenada\n",
        "    base_model = MobileNetV3Large(\n",
        "        input_shape=(*image_size, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Congelar TODAS las capas base (NO fine-tuning)\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # ARQUITECTURA 384 ‚Üí 192\n",
        "    inputs = tf.keras.Input(shape=(*image_size, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    # Primera capa densa: 384 neuronas\n",
        "    x = Dense(384, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    \n",
        "    # Segunda capa densa: 192 neuronas\n",
        "    x = Dense(192, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.35)(x)\n",
        "    \n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    # Cosine Decay ajustado a 80 √©pocas\n",
        "    lr_schedule = CosineDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=steps_per_epoch * total_epochs,\n",
        "        alpha=0.1  # LR final = 10% del inicial\n",
        "    )\n",
        "    \n",
        "    # Compilar\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr_schedule),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Crear modelo\n",
        "print(\"\\nüèóÔ∏è Creando modelo ULTIMATE V2...\\n\")\n",
        "steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
        "\n",
        "model = create_ultimate_v2_model(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    initial_learning_rate=LEARNING_RATE,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    total_epochs=EPOCHS\n",
        ")\n",
        "\n",
        "print(f\"üìê Total par√°metros: {model.count_params():,}\")\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"üìê Par√°metros entrenables: {trainable_params:,}\")\n",
        "print(f\"üìê Ratio datos/params: {train_gen.samples / trainable_params:.2f}\")\n",
        "print(\"\\n‚úÖ Modelo ULTIMATE V2 creado (SIN fine-tuning)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ BLOQUE 3: Entrenamiento (80 √©pocas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callbacks optimizados\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_ultimate_v2_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üöÄ INICIANDO ENTRENAMIENTO ULTIMATE V2\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(\"Objetivo: >85% accuracy, >80% recall\")\n",
        "print(\"Arquitectura: 384‚Üí192 (V2 sin fine-tuning)\")\n",
        "print(f\"√âpocas: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: Cosine Decay desde {LEARNING_RATE}\")\n",
        "print(f\"\\nV1 alcanz√≥ 83.81% en √©poca 60\")\n",
        "print(f\"V2 espera alcanzar >85% en √©pocas 60-80\\n\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"‚è±Ô∏è  Tiempo: {training_time/60:.2f} minutos\")\n",
        "print(f\"üìä Mejor Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%) en √©poca {best_epoch}\")\n",
        "print(f\"üìä Train Accuracy final: {history.history['accuracy'][-1]:.4f}\")\n",
        "\n",
        "if best_val_acc >= 0.85:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO ALCANZADO! (>85%)\")\n",
        "else:\n",
        "    gap = (0.85 - best_val_acc) * 100\n",
        "    print(f\"\\n‚ö†Ô∏è  Faltaron {gap:.2f} puntos porcentuales para 85%\")\n",
        "\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä BLOQUE 4: Evaluaci√≥n y Guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "from datetime import datetime\n",
        "from utils import evaluate_model, plot_training_history, plot_confusion_matrix, save_training_log\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìä EVALUACI√ìN EN TEST SET\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Evaluar modelo en test set\n",
        "evaluation_results = evaluate_model(model, test_gen, CLASSES)\n",
        "\n",
        "test_acc = evaluation_results['test_accuracy']\n",
        "test_loss = evaluation_results['test_loss']\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìà RESULTADOS FINALES\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "\n",
        "# Verificar objetivos\n",
        "if test_acc >= 0.85:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO DE ACCURACY ALCANZADO! (>85%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Accuracy por debajo del objetivo: {test_acc:.4f} < 0.85\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìã M√âTRICAS POR CLASE\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "recall_objetivo_alcanzado = True\n",
        "for class_name in CLASSES:\n",
        "    metrics = evaluation_results['classification_report'][class_name]\n",
        "    recall = metrics['recall']\n",
        "    precision = metrics['precision']\n",
        "    f1 = metrics['f1-score']\n",
        "    \n",
        "    status = \"‚úÖ\" if recall >= 0.80 else \"‚ùå\"\n",
        "    \n",
        "    print(f\"\\n{status} {class_name}:\")\n",
        "    print(f\"  Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "    print(f\"  Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "    print(f\"  F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "    \n",
        "    if recall < 0.80:\n",
        "        recall_objetivo_alcanzado = False\n",
        "\n",
        "if recall_objetivo_alcanzado:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO DE RECALL ALCANZADO EN TODAS LAS CLASES! (>80%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Algunas clases tienen recall < 80%\")\n",
        "\n",
        "print(f\"\\n{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar resultados\n",
        "print(\"üíæ Guardando resultados...\\n\")\n",
        "\n",
        "# 1. Gr√°fico de entrenamiento\n",
        "plot_path = LOGS_DIR / 'mobilenetv3_ultimate_v2_training_history.png'\n",
        "plot_training_history(history, plot_path)\n",
        "print(f\"‚úÖ Gr√°fico guardado: {plot_path}\")\n",
        "\n",
        "# 2. Matriz de confusi√≥n\n",
        "cm_path = LOGS_DIR / 'mobilenetv3_ultimate_v2_confusion_matrix.png'\n",
        "cm = plot_confusion_matrix(\n",
        "    evaluation_results['y_true'],\n",
        "    evaluation_results['y_pred'],\n",
        "    CLASSES,\n",
        "    cm_path\n",
        ")\n",
        "print(f\"‚úÖ Matriz de confusi√≥n guardada: {cm_path}\")\n",
        "\n",
        "# 3. Modelo final\n",
        "model_path = MODELS_DIR / 'mobilenetv3_ultimate_v2_final.keras'\n",
        "model.save(str(model_path))\n",
        "print(f\"‚úÖ Modelo final guardado: {model_path}\")\n",
        "\n",
        "# 4. Log detallado\n",
        "hyperparameters = {\n",
        "    'model_name': 'MobileNetV3-Large ULTIMATE V2',\n",
        "    'version': 'V2 - Sin fine-tuning',\n",
        "    'architecture': 'Dense(384)->Dense(192)',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'epochs': EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'lr_schedule': 'CosineDecay',\n",
        "    'optimizer': 'Adam',\n",
        "    'dropout': [0.4, 0.35],\n",
        "    'l2_regularization': 0.001,\n",
        "    'fine_tuning': 'Disabled (prevented catastrophic collapse)'\n",
        "}\n",
        "\n",
        "log_path = LOGS_DIR / 'mobilenetv3_ultimate_v2_training_log.json'\n",
        "\n",
        "save_training_log(\n",
        "    log_path,\n",
        "    'MobileNetV3-Large ULTIMATE V2',\n",
        "    hyperparameters,\n",
        "    history,\n",
        "    evaluation_results,\n",
        "    cm,\n",
        "    training_time\n",
        ")\n",
        "print(f\"‚úÖ Log guardado: {log_path}\")\n",
        "\n",
        "# 5. Resumen final\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üéâ ¬°ENTRENAMIENTO ULTIMATE V2 COMPLETADO!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"‚è±Ô∏è  Tiempo total: {training_time/60:.2f} minutos\")\n",
        "print(f\"üìä Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"üìä Objetivo Accuracy (>85%): {'‚úÖ ALCANZADO' if test_acc >= 0.85 else '‚ùå NO ALCANZADO'}\")\n",
        "print(f\"üìä Objetivo Recall (>80%): {'‚úÖ ALCANZADO' if recall_objetivo_alcanzado else '‚ùå NO ALCANZADO'}\")\n",
        "print(f\"\\nüíæ Archivos guardados en:\")\n",
        "print(f\"   ‚Ä¢ Modelo: {model_path}\")\n",
        "print(f\"   ‚Ä¢ Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nüìù Mejoras vs V1:\")\n",
        "print(f\"   ‚Ä¢ V1: 83.81% ‚Üí Colapso a 58.02% con fine-tuning\")\n",
        "print(f\"   ‚Ä¢ V2: {test_acc*100:.2f}% SIN fine-tuning catastr√≥fico\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
