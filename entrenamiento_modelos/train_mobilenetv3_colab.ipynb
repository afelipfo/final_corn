{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåΩ Entrenamiento MobileNetV3 - Corn Diseases Detection\n",
        "\n",
        "**Arquitectura 10/10** - Optimizada para >85% accuracy y >80% recall\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Pasos:\n",
        "1. ‚úÖ Setup y Verificaci√≥n\n",
        "2. ‚úÖ Configuraci√≥n y Modelo\n",
        "3. ‚úÖ Entrenamiento Inicial (40 √©pocas)\n",
        "4. ‚úÖ Fine-tuning (20 √©pocas)\n",
        "5. ‚úÖ Evaluaci√≥n y Guardado"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß BLOQUE 1: Setup y Verificaci√≥n"
      ],
      "metadata": {
        "id": "block1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1.2 Clonar repositorio\n",
        "!git clone -b main https://github.com/ojgonzalezz/corn-diseases-detection.git\n",
        "%cd corn-diseases-detection/entrenamiento_modelos\n",
        "\n",
        "# 1.3 Instalar dependencias\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# 1.4 Crear directorios necesarios en Drive\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/models\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/logs\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/mlruns\n",
        "\n",
        "print(\"\\n‚úÖ Setup completado!\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è BLOQUE 2: Configuraci√≥n y Creaci√≥n del Modelo"
      ],
      "metadata": {
        "id": "block2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Importar configuraci√≥n\n",
        "from config import *\n",
        "from utils import *\n",
        "\n",
        "# Configurar GPU\n",
        "setup_gpu(GPU_MEMORY_LIMIT)\n",
        "\n",
        "# Crear generadores de datos\n",
        "print(\"\\nCreando generadores de datos...\")\n",
        "train_gen, val_gen, test_gen = create_data_generators(\n",
        "    DATA_DIR, IMAGE_SIZE, BATCH_SIZE, TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT, RANDOM_SEED, DATA_AUGMENTATION\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Dataset:\")\n",
        "print(f\"  Training:   {train_gen.samples} im√°genes\")\n",
        "print(f\"  Validation: {val_gen.samples} im√°genes\")\n",
        "print(f\"  Test:       {test_gen.samples} im√°genes\")\n",
        "\n",
        "# Calcular class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_gen.classes),\n",
        "    y=train_gen.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(f\"\\n‚öñÔ∏è Class weights: {class_weight_dict}\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuraci√≥n completada!\")"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear modelo con arquitectura 10/10\n",
        "def create_mobilenetv3_model(num_classes, image_size, learning_rate):\n",
        "    \"\"\"Crear modelo MobileNetV3-Large con arquitectura 10/10\"\"\"\n",
        "    \n",
        "    # Cargar base preentrenada\n",
        "    base_model = MobileNetV3Large(\n",
        "        input_shape=(*image_size, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Congelar capas base inicialmente\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Arquitectura 10/10: Dense(256) ‚Üí Dense(128)\n",
        "    inputs = tf.keras.Input(shape=(*image_size, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.35)(x)\n",
        "    \n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    # Compilar\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Crear modelo\n",
        "print(\"\\nüèóÔ∏è Creando modelo MobileNetV3-Large...\")\n",
        "model = create_mobilenetv3_model(NUM_CLASSES, IMAGE_SIZE, LEARNING_RATE)\n",
        "print(f\"üìê Total par√°metros: {model.count_params():,}\")\n",
        "print(\"\\n‚úÖ Modelo creado!\")"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ BLOQUE 3: Entrenamiento Inicial (40 √©pocas)"
      ],
      "metadata": {
        "id": "block3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks para entrenamiento inicial\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=REDUCE_LR_PATIENCE,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\nüöÄ Iniciando entrenamiento inicial...\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\n‚úÖ Entrenamiento completado en {training_time/60:.2f} minutos\")\n",
        "print(f\"üìä Mejor Val Accuracy: {max(history.history['val_accuracy']):.4f}\")"
      ],
      "metadata": {
        "id": "training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ BLOQUE 4: Fine-tuning (20 √©pocas)"
      ],
      "metadata": {
        "id": "block4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüéØ Iniciando fine-tuning...\\n\")\n",
        "\n",
        "# Descongelar solo las √∫ltimas 20 capas\n",
        "base_model = model.layers[1]\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "trainable_layers = sum([1 for layer in base_model.layers if layer.trainable])\n",
        "print(f\"üîì Capas descongeladas: {trainable_layers} de {len(base_model.layers)}\\n\")\n",
        "\n",
        "# Recompilar con LR m√°s bajo\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE * 0.05),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks para fine-tuning\n",
        "finetune_callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=8,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=4,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# Fine-tuning\n",
        "history_finetune = model.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=finetune_callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Combinar historiales\n",
        "for key in history.history:\n",
        "    history.history[key].extend(history_finetune.history[key])\n",
        "\n",
        "finetune_time = time.time() - start_time - training_time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Fine-tuning completado en {finetune_time/60:.2f} minutos\")\n",
        "print(f\"‚è±Ô∏è Tiempo total: {total_time/60:.2f} minutos\")"
      ],
      "metadata": {
        "id": "finetuning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä BLOQUE 5: Evaluaci√≥n y Guardado de Resultados"
      ],
      "metadata": {
        "id": "block5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"\\nüìä Evaluando modelo en test set...\\n\")\n",
        "\n",
        "# Evaluar modelo\n",
        "evaluation_results = evaluate_model(model, test_gen, CLASSES)\n",
        "\n",
        "print(f\"\\n‚úÖ RESULTADOS FINALES:\")\n",
        "print(f\"  Test Accuracy: {evaluation_results['test_accuracy']:.4f} ({evaluation_results['test_accuracy']*100:.2f}%)\")\n",
        "print(f\"  Test Loss:     {evaluation_results['test_loss']:.4f}\")\n",
        "\n",
        "# Mostrar m√©tricas por clase\n",
        "print(f\"\\nüìã M√©tricas por Clase:\")\n",
        "for class_name in CLASSES:\n",
        "    metrics = evaluation_results['classification_report'][class_name]\n",
        "    print(f\"\\n  {class_name}:\")\n",
        "    print(f\"    Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"    Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"    F1-Score:  {metrics['f1-score']:.4f}\")\n",
        "\n",
        "# Guardar gr√°ficos\n",
        "plot_path = LOGS_DIR / 'mobilenetv3_training_history.png'\n",
        "plot_training_history(history, plot_path)\n",
        "print(f\"\\nüíæ Gr√°fico guardado: {plot_path}\")\n",
        "\n",
        "# Matriz de confusi√≥n\n",
        "cm_path = LOGS_DIR / 'mobilenetv3_confusion_matrix.png'\n",
        "cm = plot_confusion_matrix(\n",
        "    evaluation_results['y_true'],\n",
        "    evaluation_results['y_pred'],\n",
        "    CLASSES,\n",
        "    cm_path\n",
        ")\n",
        "print(f\"üíæ Matriz de confusi√≥n guardada: {cm_path}\")\n",
        "\n",
        "# Guardar modelo final\n",
        "model_path = MODELS_DIR / 'mobilenetv3_final.keras'\n",
        "model.save(str(model_path))\n",
        "print(f\"üíæ Modelo final guardado: {model_path}\")\n",
        "\n",
        "# Guardar log JSON\n",
        "hyperparameters = {\n",
        "    'model_name': 'MobileNetV3-Large',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'epochs': EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'architecture': 'Dense(256)->Dense(128) [10/10]'\n",
        "}\n",
        "\n",
        "log_path = LOGS_DIR / 'mobilenetv3_training_log.json'\n",
        "save_training_log(\n",
        "    log_path,\n",
        "    'MobileNetV3-Large',\n",
        "    hyperparameters,\n",
        "    history,\n",
        "    evaluation_results,\n",
        "    cm,\n",
        "    total_time\n",
        ")\n",
        "print(f\"üíæ Log guardado: {log_path}\")\n",
        "\n",
        "print(\"\\nüéâ ¬°ENTRENAMIENTO COMPLETADO EXITOSAMENTE!\")"
      ],
      "metadata": {
        "id": "evaluation"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
