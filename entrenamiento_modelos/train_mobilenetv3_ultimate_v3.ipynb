{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåΩ Entrenamiento MobileNetV3 - ULTIMATE V3 (BATCH 64 + MIXED PRECISION)\n",
        "\n",
        "**Objetivo: >85% Accuracy + >80% Recall**\n",
        "\n",
        "## üéØ Mejoras en V3:\n",
        "1. ‚úÖ **Batch size 64** (optimizado para A100)\n",
        "2. ‚úÖ **Mixed Precision Training** (2x velocidad)\n",
        "3. ‚úÖ **80 √©pocas** (probado en V2)\n",
        "4. ‚úÖ **Sin fine-tuning** (evita colapso)\n",
        "5. ‚úÖ Arquitectura 384‚Üí192 (probada y funcional)\n",
        "\n",
        "## üìä Resultados previos:\n",
        "- **V1 (60 √©pocas, batch 32):** 83.81% ‚Üí Colapso a 58% con fine-tuning\n",
        "- **V2 (80 √©pocas, batch 32):** 84.53% ‚úÖ Recall >80% en TODAS las clases\n",
        "- **V3 (80 √©pocas, batch 64 + FP16):** Objetivo >85% en ~45-50min\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß BLOQUE 1: Setup y Verificaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1.2 Clonar repositorio\n",
        "!git clone -b main https://github.com/ojgonzalezz/corn-diseases-detection.git\n",
        "%cd corn-diseases-detection/entrenamiento_modelos\n",
        "\n",
        "# 1.3 Instalar dependencias\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# 1.4 Crear directorios necesarios en Drive\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/models\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/logs\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/mlruns\n",
        "\n",
        "print(\"\\n‚úÖ Setup completado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° BLOQUE 2: Activar Mixed Precision (A100 Optimizado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Activar mixed precision para A100 (usa Tensor Cores)\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"‚ö° MIXED PRECISION ACTIVADO\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Compute dtype: {policy.compute_dtype}\")\n",
        "print(f\"Variable dtype: {policy.variable_dtype}\")\n",
        "print(f\"\\n‚úÖ Tensor Cores de A100 activados (velocidad 2x)\")\n",
        "print(f\"‚úÖ Accuracy esperado: Sin degradaci√≥n (<0.1%)\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è BLOQUE 3: Configuraci√≥n y Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Importar configuraci√≥n base\n",
        "from config import *\n",
        "from utils import setup_gpu\n",
        "\n",
        "# ==================== CONFIGURACI√ìN V3 OPTIMIZADA ====================\n",
        "BATCH_SIZE = 64  # Duplicado de 32 ‚Üí 64 (√≥ptimo para A100)\n",
        "EPOCHS = 80  # Probado en V2\n",
        "LEARNING_RATE = 0.001  # LR inicial\n",
        "EARLY_STOPPING_PATIENCE = 25  # Paciencia para 80 √©pocas\n",
        "\n",
        "# Configurar GPU\n",
        "setup_gpu(GPU_MEMORY_LIMIT)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üöÄ CONFIGURACI√ìN ULTIMATE V3\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE} (2x vs V2)\")\n",
        "print(f\"√âpocas: {EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE} (Cosine Decay)\")\n",
        "print(f\"Mixed Precision: ACTIVADO (FP16)\")\n",
        "print(f\"Fine-tuning: DESHABILITADO\")\n",
        "print(f\"\\nTiempo estimado: 45-50 min (vs 146 min en V2)\")\n",
        "print(f\"Accuracy esperado: >85%\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear generadores de datos con BATCH SIZE 64\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"Creando generadores de datos (batch 64)...\\n\")\n",
        "\n",
        "# Solo rescale (augmentation ya aplicado en preprocessing)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "test_gen = val_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(f\"üìä Dataset:\")\n",
        "print(f\"  Training:   {train_gen.samples} im√°genes ({train_gen.samples // BATCH_SIZE} batches)\")\n",
        "print(f\"  Validation: {val_gen.samples} im√°genes ({val_gen.samples // BATCH_SIZE} batches)\")\n",
        "print(f\"  Test:       {test_gen.samples} im√°genes ({test_gen.samples // BATCH_SIZE} batches)\")\n",
        "print(f\"\\n‚ö° Batch size 64 = {(322/161):.1f}x menos pasos por √©poca\")\n",
        "\n",
        "# Calcular class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_gen.classes),\n",
        "    y=train_gen.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(f\"\\n‚öñÔ∏è Class weights: {class_weight_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear modelo ULTIMATE V3 (optimizado para FP16)\n",
        "def create_ultimate_v3_model(num_classes, image_size, initial_learning_rate, steps_per_epoch, total_epochs):\n",
        "    \"\"\"\n",
        "    Arquitectura ULTIMATE V3 - Batch 64 + Mixed Precision\n",
        "    \n",
        "    Optimizaciones:\n",
        "    - Dense(384) ‚Üí Dense(192): Probada (V2: 84.53%)\n",
        "    - Dropout(0.4, 0.35): Regularizaci√≥n √≥ptima\n",
        "    - Mixed precision compatible (FP16)\n",
        "    - Batch 64 para gradientes estables\n",
        "    \"\"\"\n",
        "    \n",
        "    # Cargar base preentrenada\n",
        "    base_model = MobileNetV3Large(\n",
        "        input_shape=(*image_size, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Congelar TODAS las capas base (NO fine-tuning)\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # ARQUITECTURA 384 ‚Üí 192\n",
        "    inputs = tf.keras.Input(shape=(*image_size, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    # Primera capa densa: 384 neuronas\n",
        "    x = Dense(384, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    \n",
        "    # Segunda capa densa: 192 neuronas\n",
        "    x = Dense(192, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.35)(x)\n",
        "    \n",
        "    # Output layer (FP32 para estabilidad num√©rica)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    # Cosine Decay ajustado a 80 √©pocas\n",
        "    lr_schedule = CosineDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=steps_per_epoch * total_epochs,\n",
        "        alpha=0.1  # LR final = 10% del inicial\n",
        "    )\n",
        "    \n",
        "    # Compilar (optimizer autom√°ticamente usa FP16 internamente)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr_schedule),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Crear modelo\n",
        "print(\"\\nüèóÔ∏è Creando modelo ULTIMATE V3...\\n\")\n",
        "steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
        "\n",
        "model = create_ultimate_v3_model(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    initial_learning_rate=LEARNING_RATE,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    total_epochs=EPOCHS\n",
        ")\n",
        "\n",
        "print(f\"üìê Total par√°metros: {model.count_params():,}\")\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"üìê Par√°metros entrenables: {trainable_params:,}\")\n",
        "print(f\"üìê Ratio datos/params: {train_gen.samples / trainable_params:.2f}\")\n",
        "print(f\"\\n‚ö° Mixed precision: {policy.compute_dtype} compute, {policy.variable_dtype} variables\")\n",
        "print(\"\\n‚úÖ Modelo ULTIMATE V3 creado (Batch 64 + FP16)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ BLOQUE 4: Entrenamiento (80 √©pocas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callbacks optimizados\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_ultimate_v3_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üöÄ INICIANDO ENTRENAMIENTO ULTIMATE V3\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(\"üéØ Objetivo: >85% accuracy, >80% recall\")\n",
        "print(\"‚ö° Optimizaciones:\")\n",
        "print(f\"   ‚Ä¢ Batch size 64 (2x gradientes m√°s estables)\")\n",
        "print(f\"   ‚Ä¢ Mixed precision FP16 (2x velocidad)\")\n",
        "print(f\"   ‚Ä¢ Arquitectura 384‚Üí192 (probada en V2)\")\n",
        "print(f\"   ‚Ä¢ Sin fine-tuning (evita colapso)\")\n",
        "print(f\"\\nüìä Resultados previos:\")\n",
        "print(f\"   ‚Ä¢ V2 (batch 32): 84.53% en 146 min\")\n",
        "print(f\"   ‚Ä¢ V3 (batch 64 + FP16): Esperado >85% en 45-50 min\")\n",
        "print(f\"\\n{'='*60}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"‚úÖ ENTRENAMIENTO V3 COMPLETADO\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"‚è±Ô∏è  Tiempo: {training_time/60:.2f} minutos\")\n",
        "print(f\"‚ö° Speedup vs V2: {146.52/training_time*60:.2f}x m√°s r√°pido\")\n",
        "print(f\"üìä Mejor Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%) en √©poca {best_epoch}\")\n",
        "print(f\"üìä Train Accuracy final: {history.history['accuracy'][-1]:.4f}\")\n",
        "\n",
        "if best_val_acc >= 0.85:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO ALCANZADO! (>85%)\")\n",
        "    improvement = (best_val_acc - 0.8453) * 100\n",
        "    print(f\"üìà Mejora vs V2: +{improvement:.2f} puntos porcentuales\")\n",
        "else:\n",
        "    gap = (0.85 - best_val_acc) * 100\n",
        "    print(f\"\\n‚ö†Ô∏è  Faltaron {gap:.2f} puntos porcentuales para 85%\")\n",
        "\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä BLOQUE 5: Evaluaci√≥n y Guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "from datetime import datetime\n",
        "from utils import evaluate_model, plot_training_history, plot_confusion_matrix, save_training_log\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìä EVALUACI√ìN EN TEST SET\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Evaluar modelo en test set\n",
        "evaluation_results = evaluate_model(model, test_gen, CLASSES)\n",
        "\n",
        "test_acc = evaluation_results['test_accuracy']\n",
        "test_loss = evaluation_results['test_loss']\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìà RESULTADOS FINALES V3\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "\n",
        "# Comparaci√≥n con V2\n",
        "v2_acc = 0.8453\n",
        "improvement = (test_acc - v2_acc) * 100\n",
        "print(f\"\\nüìä Comparaci√≥n:\")\n",
        "print(f\"   V2 (batch 32): {v2_acc*100:.2f}%\")\n",
        "print(f\"   V3 (batch 64 + FP16): {test_acc*100:.2f}%\")\n",
        "print(f\"   Diferencia: {improvement:+.2f} puntos porcentuales\")\n",
        "\n",
        "# Verificar objetivos\n",
        "if test_acc >= 0.85:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO DE ACCURACY ALCANZADO! (>85%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Accuracy: {test_acc:.4f} vs objetivo 0.85\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìã M√âTRICAS POR CLASE\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "recall_objetivo_alcanzado = True\n",
        "for class_name in CLASSES:\n",
        "    metrics = evaluation_results['classification_report'][class_name]\n",
        "    recall = metrics['recall']\n",
        "    precision = metrics['precision']\n",
        "    f1 = metrics['f1-score']\n",
        "    \n",
        "    status = \"‚úÖ\" if recall >= 0.80 else \"‚ùå\"\n",
        "    \n",
        "    print(f\"\\n{status} {class_name}:\")\n",
        "    print(f\"  Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "    print(f\"  Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "    print(f\"  F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "    \n",
        "    if recall < 0.80:\n",
        "        recall_objetivo_alcanzado = False\n",
        "\n",
        "if recall_objetivo_alcanzado:\n",
        "    print(f\"\\nüéâ ¬°OBJETIVO DE RECALL ALCANZADO EN TODAS LAS CLASES! (>80%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Algunas clases tienen recall < 80%\")\n",
        "\n",
        "print(f\"\\n{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar resultados\n",
        "print(\"üíæ Guardando resultados V3...\\n\")\n",
        "\n",
        "# 1. Gr√°fico de entrenamiento\n",
        "plot_path = LOGS_DIR / 'mobilenetv3_ultimate_v3_training_history.png'\n",
        "plot_training_history(history, plot_path)\n",
        "print(f\"‚úÖ Gr√°fico guardado: {plot_path}\")\n",
        "\n",
        "# 2. Matriz de confusi√≥n\n",
        "cm_path = LOGS_DIR / 'mobilenetv3_ultimate_v3_confusion_matrix.png'\n",
        "cm = plot_confusion_matrix(\n",
        "    evaluation_results['y_true'],\n",
        "    evaluation_results['y_pred'],\n",
        "    CLASSES,\n",
        "    cm_path\n",
        ")\n",
        "print(f\"‚úÖ Matriz de confusi√≥n guardada: {cm_path}\")\n",
        "\n",
        "# 3. Modelo final\n",
        "model_path = MODELS_DIR / 'mobilenetv3_ultimate_v3_final.keras'\n",
        "model.save(str(model_path))\n",
        "print(f\"‚úÖ Modelo final guardado: {model_path}\")\n",
        "\n",
        "# 4. Log detallado\n",
        "hyperparameters = {\n",
        "    'model_name': 'MobileNetV3-Large ULTIMATE V3',\n",
        "    'version': 'V3 - Batch 64 + Mixed Precision',\n",
        "    'architecture': 'Dense(384)->Dense(192)',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'epochs': EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'lr_schedule': 'CosineDecay',\n",
        "    'optimizer': 'Adam',\n",
        "    'dropout': [0.4, 0.35],\n",
        "    'l2_regularization': 0.001,\n",
        "    'mixed_precision': 'mixed_float16',\n",
        "    'fine_tuning': 'Disabled',\n",
        "    'gpu_optimization': 'A100 with Tensor Cores'\n",
        "}\n",
        "\n",
        "log_path = LOGS_DIR / 'mobilenetv3_ultimate_v3_training_log.json'\n",
        "\n",
        "save_training_log(\n",
        "    log_path,\n",
        "    'MobileNetV3-Large ULTIMATE V3',\n",
        "    hyperparameters,\n",
        "    history,\n",
        "    evaluation_results,\n",
        "    cm,\n",
        "    training_time\n",
        ")\n",
        "print(f\"‚úÖ Log guardado: {log_path}\")\n",
        "\n",
        "# 5. Resumen final comparativo\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üéâ ¬°ENTRENAMIENTO ULTIMATE V3 COMPLETADO!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\n‚è±Ô∏è  Tiempos de entrenamiento:\")\n",
        "print(f\"   ‚Ä¢ V2 (batch 32):        146.52 min\")\n",
        "print(f\"   ‚Ä¢ V3 (batch 64 + FP16): {training_time/60:.2f} min\")\n",
        "print(f\"   ‚Ä¢ Speedup:              {146.52/(training_time/60):.2f}x m√°s r√°pido\")\n",
        "\n",
        "print(f\"\\nüìä Test Accuracy:\")\n",
        "print(f\"   ‚Ä¢ V1 (60 √©pocas):       83.81% ‚Üí 58.02% (colapso)\")\n",
        "print(f\"   ‚Ä¢ V2 (80 √©pocas):       84.53%\")\n",
        "print(f\"   ‚Ä¢ V3 (batch 64 + FP16): {test_acc*100:.2f}%\")\n",
        "\n",
        "print(f\"\\nüéØ Objetivos:\")\n",
        "print(f\"   ‚Ä¢ Accuracy >85%: {'‚úÖ ALCANZADO' if test_acc >= 0.85 else '‚ùå NO ALCANZADO'}\")\n",
        "print(f\"   ‚Ä¢ Recall >80%:   {'‚úÖ ALCANZADO' if recall_objetivo_alcanzado else '‚ùå NO ALCANZADO'}\")\n",
        "\n",
        "print(f\"\\nüíæ Archivos guardados en:\")\n",
        "print(f\"   ‚Ä¢ Modelo: {model_path}\")\n",
        "print(f\"   ‚Ä¢ Logs: {LOGS_DIR}\")\n",
        "\n",
        "print(f\"\\n‚ö° Optimizaciones V3:\")\n",
        "print(f\"   ‚Ä¢ Batch size 64 (mejor convergencia)\")\n",
        "print(f\"   ‚Ä¢ Mixed precision FP16 (Tensor Cores A100)\")\n",
        "print(f\"   ‚Ä¢ Sin fine-tuning (estabilidad garantizada)\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
