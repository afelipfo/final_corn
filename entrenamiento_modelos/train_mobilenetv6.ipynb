{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåΩ Entrenamiento MobileNetV3 - V4 FINAL (A100 OPTIMIZADO)\n",
    "\n",
    "**Objetivo: >85% Accuracy + >80% Recall en TODAS las clases**\n",
    "\n",
    "## üéØ Estrategia V4 FINAL:\n",
    "1. ‚úÖ **Batch size 32** (probado en V2 - TODAS las clases >80% recall)\n",
    "2. ‚úÖ **100 √©pocas** (vs 80 en V2 - mayor convergencia)\n",
    "3. ‚úÖ **Mixed Precision FP16** (A100 Tensor Cores - 2x velocidad)\n",
    "4. ‚úÖ **Categorical crossentropy** (ya funciona - no cambiar)\n",
    "5. ‚úÖ **Sin fine-tuning** (evita colapso)\n",
    "6. ‚úÖ **Arquitectura 384‚Üí192** (probada)\n",
    "\n",
    "## üìä An√°lisis de resultados previos:\n",
    "\n",
    "### V2 (80 √©pocas, batch 32) - ‚úÖ CONFIGURACI√ìN GANADORA:\n",
    "- Test Accuracy: 84.53%\n",
    "- **Gray_Leaf_Spot recall: >80%** ‚úÖ\n",
    "- TODAS las clases >80% recall ‚úÖ\n",
    "\n",
    "### V3.1 SAFE (100 √©pocas, batch 64) - ‚ùå BATCH 64 FALLA:\n",
    "- Test Accuracy: 84.85% (mejor)\n",
    "- **Gray_Leaf_Spot recall: 76.60%** ‚ùå (colapso)\n",
    "- Blight: 86.18% ‚úÖ\n",
    "- Common_Rust: 87.71% ‚úÖ\n",
    "- Healthy: 88.89% ‚úÖ\n",
    "\n",
    "## üîç Conclusi√≥n:\n",
    "**Batch size 64 perjudica el aprendizaje de Gray_Leaf_Spot**\n",
    "\n",
    "**Soluci√≥n: Volver a batch 32 (V2) + aumentar a 100 √©pocas + A100 FP16**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß BLOQUE 1: Setup y Verificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 1.2 Clonar repositorio\n",
    "!git clone -b main https://github.com/ojgonzalezz/corn-diseases-detection.git\n",
    "%cd corn-diseases-detection/entrenamiento_modelos\n",
    "\n",
    "# 1.3 Instalar dependencias\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# 1.4 Crear directorios necesarios en Drive\n",
    "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/models\n",
    "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/logs\n",
    "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/mlruns\n",
    "\n",
    "print(\"\\n‚úÖ Setup completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° BLOQUE 2: Activar Mixed Precision (A100 Tensor Cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Activar mixed precision para A100 (usa Tensor Cores)\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚ö° MIXED PRECISION ACTIVADO (A100 TENSOR CORES)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Compute dtype: {policy.compute_dtype}\")\n",
    "print(f\"Variable dtype: {policy.variable_dtype}\")\n",
    "print(f\"\\n‚úÖ Velocidad esperada: 2x vs FP32\")\n",
    "print(f\"‚úÖ Accuracy degradaci√≥n: <0.1%\")\n",
    "print(f\"‚úÖ VRAM ahorro: ~40%\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è BLOQUE 3: Configuraci√≥n y Generadores (BATCH 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Importar configuraci√≥n base\n",
    "from config import *\n",
    "from utils import setup_gpu\n",
    "\n",
    "# ==================== CONFIGURACI√ìN V4 FINAL ====================\n",
    "BATCH_SIZE = 32  # PROBADO en V2 - TODAS las clases >80% recall\n",
    "EPOCHS = 120  # Aumentado de 80 (V2) a 120 para mejor convergencia\n",
    "LEARNING_RATE = 0.001  # LR inicial\n",
    "EARLY_STOPPING_PATIENCE = 30  # Paciencia para 100 √©pocas\n",
    "\n",
    "# Configurar GPU\n",
    "setup_gpu(GPU_MEMORY_LIMIT)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üöÄ CONFIGURACI√ìN V4 FINAL - A100 OPTIMIZADO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE} (probado en V2 ‚úÖ)\")\n",
    "print(f\"√âpocas: {EPOCHS} (vs 80 en V2)\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE} (Cosine Decay)\")\n",
    "print(f\"Loss: Categorical Crossentropy (ya funciona)\")\n",
    "print(f\"Mixed Precision: ACTIVADO (FP16)\")\n",
    "print(f\"Fine-tuning: DESHABILITADO\")\n",
    "print(f\"\\n‚è±Ô∏è Tiempo estimado: 140-160 min (vs 287 min en V3.1 FP32)\")\n",
    "print(f\"üìä Accuracy esperado: >85%\")\n",
    "print(f\"üìä Gray_Leaf_Spot recall esperado: >80% (como en V2)\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear generadores de datos con BATCH SIZE 32\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"Creando generadores de datos (batch 32)...\\n\")\n",
    "\n",
    "# Solo rescale (augmentation ya aplicado en preprocessing)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VAL_SPLIT + TEST_SPLIT\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "test_gen = val_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset:\")\n",
    "print(f\"  Training:   {train_gen.samples} im√°genes ({train_gen.samples // BATCH_SIZE} batches)\")\n",
    "print(f\"  Validation: {val_gen.samples} im√°genes ({val_gen.samples // BATCH_SIZE} batches)\")\n",
    "print(f\"  Test:       {test_gen.samples} im√°genes ({test_gen.samples // BATCH_SIZE} batches)\")\n",
    "print(f\"\\n‚úÖ Batch size 32: Configuraci√≥n probada en V2\")\n",
    "\n",
    "# Calcular class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_gen.classes),\n",
    "    y=train_gen.classes\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"\\n‚öñÔ∏è Class weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è BLOQUE 4: Crear Modelo (Arquitectura V2 probada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo V4 FINAL (misma arquitectura que V2)\n",
    "def create_v4_final_model(num_classes, image_size, initial_learning_rate, steps_per_epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    Arquitectura V4 FINAL - Batch 32 + 100 √©pocas + Mixed Precision\n",
    "    \n",
    "    Configuraci√≥n probada en V2:\n",
    "    - Dense(384) ‚Üí Dense(192): ‚úÖ TODAS las clases >80% recall\n",
    "    - Dropout(0.4, 0.35): ‚úÖ Regularizaci√≥n √≥ptima\n",
    "    - Batch 32: ‚úÖ Gray_Leaf_Spot aprendido correctamente\n",
    "    - Categorical crossentropy: ‚úÖ Ya funciona\n",
    "    \n",
    "    Mejoras vs V2:\n",
    "    - 100 √©pocas (vs 80): Mayor convergencia\n",
    "    - Mixed precision FP16: 2x velocidad en A100\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar base preentrenada\n",
    "    base_model = MobileNetV3Large(\n",
    "        input_shape=(*image_size, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Congelar TODAS las capas base (NO fine-tuning)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # ARQUITECTURA 384 ‚Üí 192 (probada en V2)\n",
    "    inputs = tf.keras.Input(shape=(*image_size, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Primera capa densa: 384 neuronas\n",
    "    x = Dense(384, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Segunda capa densa: 192 neuronas\n",
    "    x = Dense(192, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "    \n",
    "    # Output layer (FP32 para estabilidad num√©rica)\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Cosine Decay ajustado a 100 √©pocas\n",
    "    lr_schedule = CosineDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=steps_per_epoch * total_epochs,\n",
    "        alpha=0.1  # LR final = 10% del inicial\n",
    "    )\n",
    "    \n",
    "    # Compilar con categorical crossentropy (ya funciona)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr_schedule),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear modelo\n",
    "print(\"\\nüèóÔ∏è Creando modelo V4 FINAL (arquitectura V2 probada)...\\n\")\n",
    "steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
    "\n",
    "model = create_v4_final_model(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    total_epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"üìê Total par√°metros: {model.count_params():,}\")\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "print(f\"üìê Par√°metros entrenables: {trainable_params:,}\")\n",
    "print(f\"üìê Ratio datos/params: {train_gen.samples / trainable_params:.2f}\")\n",
    "\n",
    "print(f\"\\n‚ö° Configuraci√≥n V4 FINAL:\")\n",
    "print(f\"   ‚Ä¢ Arquitectura: Dense(384)‚ÜíDense(192) (V2 probada ‚úÖ)\")\n",
    "print(f\"   ‚Ä¢ Batch 32: Probado en V2 con >80% recall en todas las clases ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ 100 √©pocas: Mayor convergencia vs 80 (V2)\")\n",
    "print(f\"   ‚Ä¢ Mixed precision: {policy.compute_dtype} compute, {policy.variable_dtype} variables\")\n",
    "print(f\"   ‚Ä¢ Loss: Categorical crossentropy (ya funciona ‚úÖ)\")\n",
    "print(f\"   ‚Ä¢ Sin fine-tuning: Evita colapso ‚úÖ\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelo V4 FINAL creado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ BLOQUE 5: Entrenamiento (100 √©pocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks optimizados\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='max'\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        str(MODELS_DIR / 'mobilenetv3_v4_final_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        mode='max'\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO V4 FINAL\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "print(\"üéØ Objetivo: >85% accuracy, >80% recall en TODAS las clases\")\n",
    "print(\"\\nüìä Estrategia:\")\n",
    "print(f\"   ‚Ä¢ Batch 32: Configuraci√≥n probada en V2 ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ 100 √©pocas: M√°s convergencia que V2 (80 √©pocas)\")\n",
    "print(f\"   ‚Ä¢ Mixed precision FP16: 2x velocidad en A100\")\n",
    "print(f\"   ‚Ä¢ Categorical crossentropy: Ya funciona correctamente\")\n",
    "print(f\"   ‚Ä¢ Sin fine-tuning: Evita colapso\")\n",
    "print(f\"\\nüìä Resultados previos:\")\n",
    "print(f\"   ‚Ä¢ V2 (80 √©pocas, batch 32):    84.53% - ‚úÖ TODAS >80% recall\")\n",
    "print(f\"   ‚Ä¢ V3.1 (100 √©pocas, batch 64): 84.85% - ‚ùå Gray_Leaf_Spot 76.60%\")\n",
    "print(f\"   ‚Ä¢ V4 FINAL (100 √©pocas, batch 32 + FP16): Esperado >85% + todas >80%\")\n",
    "print(f\"\\n‚è±Ô∏è Tiempo estimado: 140-160 min (2x m√°s r√°pido que V3.1 FP32)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ ENTRENAMIENTO V4 FINAL COMPLETADO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"‚è±Ô∏è  Tiempo: {training_time/60:.2f} minutos\")\n",
    "print(f\"‚ö° Speedup vs V3.1 FP32: {287.78/(training_time/60):.2f}x m√°s r√°pido\")\n",
    "print(f\"üìä Mejor Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%) en √©poca {best_epoch}\")\n",
    "print(f\"üìä Train Accuracy final: {history.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "if best_val_acc >= 0.85:\n",
    "    print(f\"\\nüéâ ¬°OBJETIVO DE ACCURACY ALCANZADO! (>85%)\")\n",
    "    improvement = (best_val_acc - 0.8485) * 100\n",
    "    print(f\"üìà Mejora vs V3.1: +{improvement:.2f} puntos porcentuales\")\n",
    "else:\n",
    "    gap = (0.85 - best_val_acc) * 100\n",
    "    print(f\"\\n‚ö†Ô∏è  Faltaron {gap:.2f} puntos porcentuales para 85%\")\n",
    "\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä BLOQUE 6: Evaluaci√≥n Detallada y Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "from datetime import datetime\n",
    "from utils import evaluate_model, plot_training_history, plot_confusion_matrix, save_training_log\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìä EVALUACI√ìN EN TEST SET\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Evaluar modelo en test set\n",
    "evaluation_results = evaluate_model(model, test_gen, CLASSES)\n",
    "\n",
    "test_acc = evaluation_results['test_accuracy']\n",
    "test_loss = evaluation_results['test_loss']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìà RESULTADOS FINALES V4 FINAL\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "\n",
    "# Comparaci√≥n con versiones anteriores\n",
    "v2_acc = 0.8453\n",
    "v31_acc = 0.8485\n",
    "improvement_v2 = (test_acc - v2_acc) * 100\n",
    "improvement_v31 = (test_acc - v31_acc) * 100\n",
    "\n",
    "print(f\"\\nüìä Comparaci√≥n:\")\n",
    "print(f\"   V2 (80 √©pocas, batch 32):     {v2_acc*100:.2f}%\")\n",
    "print(f\"   V3.1 (100 √©pocas, batch 64):  {v31_acc*100:.2f}%\")\n",
    "print(f\"   V4 FINAL (100 √©pocas, batch 32 + FP16): {test_acc*100:.2f}%\")\n",
    "print(f\"   Mejora vs V2:     {improvement_v2:+.2f} puntos\")\n",
    "print(f\"   Mejora vs V3.1:   {improvement_v31:+.2f} puntos\")\n",
    "\n",
    "# Verificar objetivo de accuracy\n",
    "if test_acc >= 0.85:\n",
    "    print(f\"\\nüéâ ¬°OBJETIVO DE ACCURACY ALCANZADO! (>85%)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Accuracy: {test_acc:.4f} vs objetivo 0.85\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìã M√âTRICAS POR CLASE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "recall_objetivo_alcanzado = True\n",
    "gray_leaf_spot_recall = 0.0\n",
    "\n",
    "for class_name in CLASSES:\n",
    "    metrics = evaluation_results['classification_report'][class_name]\n",
    "    recall = metrics['recall']\n",
    "    precision = metrics['precision']\n",
    "    f1 = metrics['f1-score']\n",
    "    \n",
    "    # Guardar recall de Gray_Leaf_Spot\n",
    "    if 'Gray' in class_name or 'gray' in class_name.lower():\n",
    "        gray_leaf_spot_recall = recall\n",
    "    \n",
    "    status = \"‚úÖ\" if recall >= 0.80 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status} {class_name}:\")\n",
    "    print(f\"  Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"  Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"  F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    \n",
    "    if recall < 0.80:\n",
    "        recall_objetivo_alcanzado = False\n",
    "\n",
    "# Verificar objetivo de recall\n",
    "if recall_objetivo_alcanzado:\n",
    "    print(f\"\\nüéâ ¬°OBJETIVO DE RECALL ALCANZADO EN TODAS LAS CLASES! (>80%)\")\n",
    "    if gray_leaf_spot_recall > 0:\n",
    "        improvement_gls = (gray_leaf_spot_recall - 0.7660) * 100\n",
    "        print(f\"\\nüåü Gray_Leaf_Spot: {gray_leaf_spot_recall*100:.2f}% (mejora de {improvement_gls:+.2f} puntos vs V3.1)\")\n",
    "        print(f\"‚úÖ Batch 32 funciona correctamente para Gray_Leaf_Spot (como en V2)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Algunas clases tienen recall < 80%\")\n",
    "\n",
    "# Resumen final\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéØ VERIFICACI√ìN DE OBJETIVOS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"‚úì Accuracy >85%: {'‚úÖ S√ç' if test_acc >= 0.85 else '‚ùå NO'} ({test_acc*100:.2f}%)\")\n",
    "print(f\"‚úì Recall >80%:   {'‚úÖ S√ç' if recall_objetivo_alcanzado else '‚ùå NO'} (todas las clases)\")\n",
    "\n",
    "if test_acc >= 0.85 and recall_objetivo_alcanzado:\n",
    "    print(f\"\\nüèÜ ¬°AMBOS OBJETIVOS ALCANZADOS!\")\n",
    "    print(f\"\\n‚úÖ Estrategia correcta:\")\n",
    "    print(f\"   ‚Ä¢ Batch 32 (probado en V2)\")\n",
    "    print(f\"   ‚Ä¢ 100 √©pocas (mayor convergencia)\")\n",
    "    print(f\"   ‚Ä¢ Mixed precision FP16 (2x velocidad)\")\n",
    "    print(f\"   ‚Ä¢ Categorical crossentropy (ya funciona)\")\n",
    "\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ BLOQUE 7: Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados\n",
    "print(\"üíæ Guardando resultados V4 FINAL...\\n\")\n",
    "\n",
    "# 1. Gr√°fico de entrenamiento\n",
    "plot_path = LOGS_DIR / 'mobilenetv3_v4_final_training_history.png'\n",
    "plot_training_history(history, plot_path)\n",
    "print(f\"‚úÖ Gr√°fico guardado: {plot_path}\")\n",
    "\n",
    "# 2. Matriz de confusi√≥n\n",
    "cm_path = LOGS_DIR / 'mobilenetv3_v4_final_confusion_matrix.png'\n",
    "cm = plot_confusion_matrix(\n",
    "    evaluation_results['y_true'],\n",
    "    evaluation_results['y_pred'],\n",
    "    CLASSES,\n",
    "    cm_path\n",
    ")\n",
    "print(f\"‚úÖ Matriz de confusi√≥n guardada: {cm_path}\")\n",
    "\n",
    "# 3. Modelo final\n",
    "model_path = MODELS_DIR / 'mobilenetv3_v4_final.keras'\n",
    "model.save(str(model_path))\n",
    "print(f\"‚úÖ Modelo final guardado: {model_path}\")\n",
    "\n",
    "# 4. Log detallado\n",
    "hyperparameters = {\n",
    "    'model_name': 'MobileNetV3-Large V4 FINAL',\n",
    "    'version': 'V4 FINAL - Batch 32 + 120 √©pocas + A100 FP16',\n",
    "    'architecture': 'Dense(384)->Dense(192)',\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'lr_schedule': 'CosineDecay',\n",
    "    'optimizer': 'Adam',\n",
    "    'loss_function': 'categorical_crossentropy',\n",
    "    'dropout': [0.4, 0.35],\n",
    "    'l2_regularization': 0.001,\n",
    "    'mixed_precision': 'mixed_float16',\n",
    "    'fine_tuning': 'Disabled',\n",
    "    'gpu_optimization': 'A100 24GB with Tensor Cores',\n",
    "    'strategy': 'Batch 32 from V2 (proven) + 120 epochs (better convergence) + FP16 (2x speed)'\n",
    "}\n",
    "\n",
    "log_path = LOGS_DIR / 'mobilenetv3_v4_final_training_log.json'\n",
    "\n",
    "save_training_log(\n",
    "    log_path,\n",
    "    'MobileNetV3-Large V4 FINAL',\n",
    "    hyperparameters,\n",
    "    history,\n",
    "    evaluation_results,\n",
    "    cm,\n",
    "    training_time\n",
    ")\n",
    "print(f\"‚úÖ Log guardado: {log_path}\")\n",
    "\n",
    "# 5. Resumen final comparativo\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéâ ¬°ENTRENAMIENTO V4 FINAL COMPLETADO!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Tiempos de entrenamiento:\")\n",
    "print(f\"   ‚Ä¢ V2 (80 √©pocas, batch 32, FP32):  146.52 min\")\n",
    "print(f\"   ‚Ä¢ V3.1 (100 √©pocas, batch 64, FP32): 287.78 min\")\n",
    "print(f\"   ‚Ä¢ V4 FINAL (100 √©pocas, batch 32, FP16): {training_time/60:.2f} min\")\n",
    "print(f\"   ‚Ä¢ Speedup vs V2:   {146.52/(training_time/60):.2f}x\")\n",
    "print(f\"   ‚Ä¢ Speedup vs V3.1: {287.78/(training_time/60):.2f}x\")\n",
    "\n",
    "print(f\"\\nüìä Test Accuracy:\")\n",
    "print(f\"   ‚Ä¢ V2 (80 √©pocas, batch 32):      84.53%\")\n",
    "print(f\"   ‚Ä¢ V3.1 (100 √©pocas, batch 64):   84.85%\")\n",
    "print(f\"   ‚Ä¢ V4 FINAL (100 √©pocas, batch 32 + FP16): {test_acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã Gray_Leaf_Spot Recall (problema clave):\")\n",
    "print(f\"   ‚Ä¢ V2 (batch 32):  >80% ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ V3.1 (batch 64): 76.60% ‚ùå\")\n",
    "if gray_leaf_spot_recall > 0:\n",
    "    print(f\"   ‚Ä¢ V4 FINAL (batch 32): {gray_leaf_spot_recall*100:.2f}% {'‚úÖ' if gray_leaf_spot_recall >= 0.80 else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüéØ Objetivos:\")\n",
    "print(f\"   ‚Ä¢ Accuracy >85%: {'‚úÖ ALCANZADO' if test_acc >= 0.85 else '‚ùå NO ALCANZADO'}\")\n",
    "print(f\"   ‚Ä¢ Recall >80%:   {'‚úÖ ALCANZADO' if recall_objetivo_alcanzado else '‚ùå NO ALCANZADO'}\")\n",
    "\n",
    "print(f\"\\nüíæ Archivos guardados en:\")\n",
    "print(f\"   ‚Ä¢ Modelo: {model_path}\")\n",
    "print(f\"   ‚Ä¢ Logs: {LOGS_DIR}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Estrategia V4 FINAL:\")\n",
    "print(f\"   ‚Ä¢ Batch 32: Configuraci√≥n probada en V2 (>80% recall todas las clases)\")\n",
    "print(f\"   ‚Ä¢ 100 √©pocas: Mayor convergencia vs V2 (80 √©pocas)\")\n",
    "print(f\"   ‚Ä¢ Mixed precision FP16: 2x velocidad en A100 Tensor Cores\")\n",
    "print(f\"   ‚Ä¢ Categorical crossentropy: Ya funciona correctamente\")\n",
    "print(f\"   ‚Ä¢ Sin fine-tuning: Estabilidad garantizada\")\n",
    "\n",
    "print(f\"\\nüîç Conclusi√≥n: Batch size 64 perjudicaba Gray_Leaf_Spot\")\n",
    "print(f\"‚úÖ Soluci√≥n: Volver a batch 32 + aumentar √©pocas + FP16 para velocidad\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
