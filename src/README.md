# ğŸŒ½ cornIA - Corn Disease Classification

ClasificaciÃ³n automÃ¡tica de enfermedades en maÃ­z usando Deep Learning con **MobileNetV3Large**.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ DescripciÃ³n

Pipeline completo de Machine Learning para clasificar 4 tipos de condiciones en hojas de maÃ­z:

- **Blight** (TizÃ³n)
- **CommonRust** (Roya comÃºn)
- **GrayLeafSpot** (Mancha gris)
- **Healthy** (Sano)

### CaracterÃ­sticas principales:

âœ… **Transfer Learning** con MobileNetV3Large (ImageNet)
âœ… **Data Augmentation** hÃ­brida (offline + online)
âœ… **Dataset balanceado** (916 imÃ¡genes por clase en train)
âœ… **Callbacks inteligentes** (EarlyStopping, ReduceLROnPlateau)
âœ… **MÃ©tricas completas** (Accuracy, Precision, Recall, F1, AUC)
âœ… **MLflow** para tracking de experimentos
âœ… **Google Colab** compatible (GPU L4)

---

## ğŸš€ Inicio RÃ¡pido

### **OpciÃ³n 1: Google Colab (Recomendado)**

1. **Sube `data_augmented/` a Google Drive:**
   ```
   Mi unidad/
   â””â”€â”€ data_augmented/
       â”œâ”€â”€ train/
       â”œâ”€â”€ val/
       â””â”€â”€ test/
   ```

2. **Abre el notebook en Colab:**

   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/afelipfo/cornIA/blob/main/corn_disease_training.ipynb)

3. **Activa GPU L4:**
   - Runtime â†’ Change runtime type â†’ GPU â†’ L4

4. **Ejecuta las celdas secuencialmente**

---

### **OpciÃ³n 2: EjecuciÃ³n Local**

```bash
# 1. Clonar repositorio
git clone https://github.com/afelipfo/cornIA.git
cd cornIA

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Descargar dataset (desde tu Google Drive)
# Coloca data_augmented/ en la raÃ­z del proyecto

# 4. Ejecutar pipeline completo
python src/run_pipeline.py
```

---

## ğŸ“‚ Estructura del Proyecto

```
cornIA/
â”œâ”€â”€ src/                              # Scripts del pipeline
â”‚   â”œâ”€â”€ training_config.py           # Paso 4: ConfiguraciÃ³n
â”‚   â”œâ”€â”€ model_creation.py            # Paso 5: Modelo
â”‚   â”œâ”€â”€ train_model.py               # Paso 6: Entrenamiento
â”‚   â”œâ”€â”€ evaluate_and_export.py       # Paso 7: EvaluaciÃ³n
â”‚   â””â”€â”€ run_pipeline.py              # Orquestador completo
â”‚
â”œâ”€â”€ corn_disease_training.ipynb      # Notebook para Google Colab
â”œâ”€â”€ requirements.txt                 # Dependencias Python
â”œâ”€â”€ .gitignore                       # Archivos ignorados por Git
â””â”€â”€ README.md                        # Este archivo

# Carpetas generadas durante ejecuciÃ³n (no en Git):
â”œâ”€â”€ data_augmented/                  # Dataset (en Google Drive)
â”œâ”€â”€ training_output/                 # ConfiguraciÃ³n + modelo entrenado
â”œâ”€â”€ model_output/                    # Arquitectura del modelo
â”œâ”€â”€ training_results/                # GrÃ¡ficas + mÃ©tricas
â””â”€â”€ evaluation_results/              # EvaluaciÃ³n en test set
```

---

## ğŸ¯ Pipeline de Entrenamiento

El pipeline consta de **4 pasos** principales:

### **Paso 4: ConfiguraciÃ³n de Entrenamiento**
- Data augmentation online (rotaciÃ³n, shifts, flips, brillo, zoom)
- Generadores de datos (train/val/test)
- Callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, etc.)

### **Paso 5: CreaciÃ³n del Modelo**
- MobileNetV3Large preentrenado (ImageNet)
- BatchNormalization
- Dropout (0.5)
- Dense (4 clases, softmax)

### **Paso 6: Entrenamiento**
- 50 Ã©pocas (con EarlyStopping)
- Batch size: 32
- Optimizer: Adam (lr=0.001)
- Loss: categorical_crossentropy
- MÃ©tricas: Accuracy, Precision, Recall, AUC

### **Paso 7: EvaluaciÃ³n y MLflow**
- EvaluaciÃ³n en test set (sin augmentation)
- Matriz de confusiÃ³n
- Classification report
- Registro completo en MLflow

---

## ğŸ“Š Dataset

### DistribuciÃ³n (despuÃ©s de augmentation offline):

| Clase | Train | Val | Test | Total |
|-------|-------|-----|------|-------|
| Blight | 916 | 177 | 176 | 1,269 |
| CommonRust | 916 | 196 | 196 | 1,308 |
| GrayLeafSpot | 916 | 87 | 87 | 1,090 |
| Healthy | 916 | 174 | 175 | 1,265 |
| **Total** | **3,664** | **634** | **634** | **4,932** |

**CaracterÃ­sticas:**
- ImÃ¡genes: 256x256 px
- Formato: JPG
- Augmentation offline aplicada para balanceo perfecto en train
- Val/Test sin modificaciÃ³n (datos originales)

---

## ğŸ”§ ConfiguraciÃ³n

### **HiperparÃ¡metros principales:**

```python
RANDOM_SEED = 42           # Reproducibilidad
EPOCHS = 50                # Ã‰pocas mÃ¡ximas
BATCH_SIZE = 32            # TamaÃ±o del batch
LEARNING_RATE = 0.001      # Tasa de aprendizaje inicial
```

### **Callbacks:**

| Callback | ParÃ¡metros |
|----------|------------|
| EarlyStopping | patience=10, monitor='val_loss' |
| ReduceLROnPlateau | factor=0.1, patience=5 |
| ModelCheckpoint | save_best_only=True, monitor='val_accuracy' |
| CSVLogger | training_history.csv |
| TensorBoard | logs en tensorboard_logs/ |

---

## ğŸ“ˆ Resultados

Los resultados varÃ­an segÃºn el entrenamiento, pero se espera:

- **Accuracy en test:** ~85-95%
- **Precision (macro):** ~85-93%
- **Recall (macro):** ~85-93%
- **F1-score (macro):** ~85-93%

Todos los resultados se guardan en:
- `training_results/training_history.png` - GrÃ¡ficas de accuracy y loss
- `evaluation_results/confusion_matrix.png` - Matriz de confusiÃ³n
- `evaluation_results/classification_report.csv` - MÃ©tricas detalladas

---

## ğŸ› ï¸ Requisitos

### **Python 3.8+**

```bash
tensorflow>=2.12.0
keras>=2.12.0
numpy>=1.23.0
pandas>=1.5.0
matplotlib>=3.6.0
seaborn>=0.12.0
scikit-learn>=1.2.0
mlflow>=2.3.0
opencv-python>=4.7.0
```

Instalar todo:
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Uso en Google Colab

### **Pasos detallados:**

1. **Sube dataset a Google Drive:**
   - Carpeta: `/Mi unidad/data_augmented/`
   - Contenido: train/, val/, test/

2. **Abre el notebook:**
   - Haz clic en el badge "Open in Colab" arriba

3. **Configura GPU:**
   - Runtime â†’ Change runtime type â†’ GPU â†’ L4

4. **Ejecuta secciÃ³n por secciÃ³n:**
   - SecciÃ³n 1: Verifica GPU âœ…
   - SecciÃ³n 2: Instala dependencias
   - SecciÃ³n 3: Monta Drive + clona GitHub
   - Secciones 4-7: Pipeline completo
   - Secciones 8-11: VisualizaciÃ³n de resultados

5. **Descarga resultados:**
   - SecciÃ³n 12: ZIP automÃ¡tico
   - SecciÃ³n 13: Guardar en Drive

**Tiempo estimado:** 45-75 minutos (con GPU L4)

---

## ğŸ”¬ MLflow Tracking

Todos los experimentos se registran en MLflow:

```python
Experiment: "Maize-Disease-Classification"

Registra:
- ParÃ¡metros (batch_size, epochs, optimizer, etc.)
- MÃ©tricas (accuracy, precision, recall, f1, auc)
- Artefactos (grÃ¡ficas, matrices, reportes)
- Modelo entrenado
- Versiones de dependencias
- Hardware utilizado
```

Ver resultados:
```bash
mlflow ui
# Abre http://localhost:5000
```

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -m 'AÃ±ade mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¤ Autor

**Felipe FlÃ³rez**
- GitHub: [@afelipfo](https://github.com/afelipfo)
- Email: afelipeflorezo@gmail.com

---

## ğŸ™ Agradecimientos

- Dataset de imÃ¡genes de enfermedades de maÃ­z
- MobileNetV3Large (Google AI)
- TensorFlow y Keras
- Google Colab por GPUs gratuitas

---

## ğŸ“š Referencias

- [MobileNetV3 Paper](https://arxiv.org/abs/1905.02244)
- [TensorFlow Documentation](https://www.tensorflow.org/)
- [MLflow Documentation](https://mlflow.org/)

---

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!**
