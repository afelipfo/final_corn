{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üåΩ Corn Disease Classification - Pipeline Completo\n",
    "\n",
    "**Pipeline de entrenamiento con MobileNetV3Large**\n",
    "\n",
    "- **Paso 4:** Configuraci√≥n de entrenamiento\n",
    "- **Paso 5:** Creaci√≥n del modelo\n",
    "- **Paso 6:** Entrenamiento\n",
    "- **Paso 7:** Evaluaci√≥n y exportaci√≥n con MLflow\n",
    "\n",
    "---\n",
    "\n",
    "**GPU Recomendada:** L4 o superior  \n",
    "**Tiempo estimado:** 30-60 minutos (depende de GPU y √©pocas)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-1"
   },
   "source": [
    "## üì¶ Secci√≥n 1: Configuraci√≥n Inicial y Verificaci√≥n de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VERIFICACI√ìN DE ENTORNO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nPython version: {sys.version.split()[0]}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Verificar GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úÖ GPU detectada: {len(gpus)} dispositivo(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   {gpu}\")\n",
    "    \n",
    "    # Configurar crecimiento de memoria\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"   Memory growth habilitado\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  NO se detect√≥ GPU - El entrenamiento ser√° MUY lento en CPU\")\n",
    "    print(\"   Recomendaci√≥n: Runtime > Change runtime type > GPU (L4)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-2"
   },
   "source": [
    "## üìÇ Secci√≥n 2: Instalaci√≥n de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Instalar dependencias necesarias\n",
    "print(\"Instalando dependencias...\\n\")\n",
    "\n",
    "!pip install -q mlflow\n",
    "!pip install -q seaborn\n",
    "\n",
    "print(\"\\n‚úÖ Dependencias instaladas correctamente\")\n",
    "\n",
    "# Verificar versiones\n",
    "import mlflow\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(f\"\\nMLflow version: {mlflow.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-3"
   },
   "source": "## üì• Secci√≥n 3: Carga del Dataset desde Google Drive y Scripts desde GitHub\n\n**Estrategia:**\n1. **Dataset (`data_augmented/`):** Montado desde Google Drive\n2. **Scripts (`src/`):** Clonados desde GitHub (repositorio `cornIA`)\n\n**Estructura esperada:**\n```\nGoogle Drive: /Mi unidad/data_augmented/\n‚îú‚îÄ‚îÄ train/ (916 imgs x 4 clases)\n‚îú‚îÄ‚îÄ val/   (634 imgs total)\n‚îî‚îÄ‚îÄ test/  (634 imgs total)\n\nGitHub: https://github.com/afelipfo/cornIA\n‚îî‚îÄ‚îÄ src/\n    ‚îú‚îÄ‚îÄ training_config.py\n    ‚îú‚îÄ‚îÄ model_creation.py\n    ‚îú‚îÄ‚îÄ train_model.py\n    ‚îî‚îÄ‚îÄ evaluate_and_export.py\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": "# Paso 1: Montar Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nprint(\"\\n‚úÖ Google Drive montado\")\n\n# Paso 2: Clonar repositorio de GitHub\nprint(\"\\nüì• Clonando repositorio de GitHub...\")\n!git clone https://github.com/afelipfo/cornIA.git\n\nprint(\"\\n‚úÖ Repositorio clonado\")\n\n# Paso 3: Copiar scripts a directorio de trabajo\nimport shutil\nimport os\n\nif os.path.exists('cornIA/src'):\n    if os.path.exists('src'):\n        shutil.rmtree('src')\n    shutil.copytree('cornIA/src', 'src')\n    print(\"‚úÖ Scripts copiados desde GitHub a ./src\")\nelse:\n    print(\"‚ö†Ô∏è  No se encontr√≥ carpeta src/ en el repositorio\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-structure"
   },
   "outputs": [],
   "source": "# Paso 4: Crear enlace simb√≥lico a data_augmented desde Google Drive\nprint(\"üìÇ Configurando acceso a dataset...\\n\")\n\n# Ruta del dataset en Google Drive (AJUSTA ESTA RUTA SEG√öN TU ESTRUCTURA)\ndrive_data_path = '/content/drive/MyDrive/data_augmented'\n\n# Verificar si existe\nif os.path.exists(drive_data_path):\n    # Crear enlace simb√≥lico\n    if os.path.exists('data_augmented'):\n        os.remove('data_augmented')\n    os.symlink(drive_data_path, 'data_augmented')\n    print(f\"‚úÖ Dataset enlazado desde: {drive_data_path}\")\nelse:\n    print(f\"‚ùå NO ENCONTRADO: {drive_data_path}\")\n    print(\"\\n‚ö†Ô∏è  ACCI√ìN REQUERIDA:\")\n    print(\"   1. Verifica que subiste data_augmented/ a Google Drive\")\n    print(\"   2. Ajusta la ruta 'drive_data_path' en esta celda\")\n    print(\"   Ejemplo: '/content/drive/MyDrive/MiCarpeta/data_augmented'\")\n\n# Paso 5: Verificar estructura completa\nprint(\"\\n\" + \"=\" * 80)\nprint(\"VERIFICANDO ESTRUCTURA DE ARCHIVOS\")\nprint(\"=\" * 80 + \"\\n\")\n\nrequired_structure = {\n    'Carpetas de datos': [\n        'data_augmented/train/Blight',\n        'data_augmented/train/CommonRust',\n        'data_augmented/train/GrayLeafSpot',\n        'data_augmented/train/Healthy',\n        'data_augmented/val',\n        'data_augmented/test'\n    ],\n    'Scripts de entrenamiento': [\n        'src/training_config.py',\n        'src/model_creation.py',\n        'src/train_model.py',\n        'src/evaluate_and_export.py'\n    ]\n}\n\nall_ok = True\nfor category, paths in required_structure.items():\n    print(f\"\\n{category}:\")\n    for path in paths:\n        if os.path.exists(path):\n            print(f\"  ‚úÖ {path}\")\n        else:\n            print(f\"  ‚ùå {path} - NO ENCONTRADO\")\n            all_ok = False\n\nif all_ok:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üéâ VERIFICACI√ìN EXITOSA - Todos los archivos est√°n listos\")\n    print(\"=\" * 80)\nelse:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"‚ö†Ô∏è  VERIFICACI√ìN FALLIDA - Corrige los errores antes de continuar\")\n    print(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-4"
   },
   "source": [
    "## üîß Secci√≥n 4: Configuraci√≥n de Par√°metros del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-params"
   },
   "outputs": [],
   "source": [
    "# Configuraci√≥n del pipeline\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFIGURACI√ìN DEL PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nRandom seed: {RANDOM_SEED}\")\n",
    "print(f\"√âpocas: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Agregar src al path para imports\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "print(\"\\n‚úÖ Par√°metros configurados\")\n",
    "print(\"‚úÖ M√≥dulos de src/ agregados al path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-5"
   },
   "source": [
    "## üéØ Secci√≥n 5: PASO 4 - Configuraci√≥n de Entrenamiento\n",
    "\n",
    "Configura:\n",
    "- Data augmentation online\n",
    "- Generadores de datos (train/val/test)\n",
    "- Callbacks (EarlyStopping, ReduceLROnPlateau, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step-4"
   },
   "outputs": [],
   "source": [
    "from training_config import TrainingConfiguration\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"‚ñì\" * 100)\n",
    "print(\"‚ñì PASO 4: CONFIGURACI√ìN DE ENTRENAMIENTO\")\n",
    "print(\"‚ñì Configura augmentation online, generadores de datos y callbacks\")\n",
    "print(\"‚ñì\" * 100 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Inicializar configuraci√≥n\n",
    "    print(\"üîß Inicializando TrainingConfiguration...\\n\")\n",
    "    config = TrainingConfiguration(\n",
    "        data_dir='./data_augmented',\n",
    "        output_dir='./training_output',\n",
    "        random_seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Ejecutar configuraci√≥n completa\n",
    "    print(\"üöÄ Ejecutando configuraci√≥n completa...\\n\")\n",
    "    config.run()\n",
    "    \n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚úÖ PASO 4 COMPLETADO: Configuraci√≥n de Entrenamiento\")\n",
    "    print(\"‚ñë\" * 100 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚ùå PASO 4 FALL√ì: Configuraci√≥n de Entrenamiento\")\n",
    "    print(\"‚ñë\" * 100)\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-6"
   },
   "source": [
    "## ü§ñ Secci√≥n 6: PASO 5 - Creaci√≥n del Modelo\n",
    "\n",
    "Crea el modelo:\n",
    "- MobileNetV3Large (ImageNet)\n",
    "- BatchNormalization\n",
    "- Dropout(0.5)\n",
    "- Dense(4, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step-5"
   },
   "outputs": [],
   "source": [
    "from model_creation import ModelCreator\n",
    "\n",
    "print(\"\\n\" + \"‚ñì\" * 100)\n",
    "print(\"‚ñì PASO 5: CREACI√ìN DEL MODELO\")\n",
    "print(\"‚ñì Crea MobileNetV3Large con BatchNorm, Dropout y capa de salida\")\n",
    "print(\"‚ñì\" * 100 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Inicializar creador de modelo\n",
    "    print(\"ü§ñ Inicializando ModelCreator...\\n\")\n",
    "    creator = ModelCreator(\n",
    "        config_path='./training_output/training_config.json',\n",
    "        output_dir='./model_output',\n",
    "        random_seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Crear y compilar modelo\n",
    "    print(\"üèóÔ∏è  Ejecutando creaci√≥n y compilaci√≥n del modelo...\\n\")\n",
    "    model = creator.run()\n",
    "    \n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚úÖ PASO 5 COMPLETADO: Creaci√≥n del Modelo\")\n",
    "    print(\"‚ñë\" * 100 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚ùå PASO 5 FALL√ì: Creaci√≥n del Modelo\")\n",
    "    print(\"‚ñë\" * 100)\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-7"
   },
   "source": [
    "## üèãÔ∏è Secci√≥n 7: PASO 6 - Entrenamiento\n",
    "\n",
    "Entrena el modelo:\n",
    "- Con augmentation online\n",
    "- Callbacks autom√°ticos\n",
    "- M√©tricas avanzadas (Precision, Recall, AUC)\n",
    "- Gr√°ficas autom√°ticas\n",
    "\n",
    "**‚ö†Ô∏è ADVERTENCIA:** Esta celda puede tardar 30-60 minutos dependiendo de la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step-6"
   },
   "outputs": [],
   "source": [
    "from train_model import ModelTrainer\n",
    "\n",
    "print(\"\\n\" + \"‚ñì\" * 100)\n",
    "print(\"‚ñì PASO 6: ENTRENAMIENTO DEL MODELO\")\n",
    "print(\"‚ñì Entrena el modelo con augmentation, callbacks y m√©tricas avanzadas\")\n",
    "print(\"‚ñì\" * 100 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Inicializar entrenador\n",
    "    print(\"üöÄ Inicializando ModelTrainer...\\n\")\n",
    "    trainer = ModelTrainer(\n",
    "        output_dir='./training_results',\n",
    "        random_seed=RANDOM_SEED,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Ejecutar entrenamiento completo\n",
    "    print(\"üèãÔ∏è  Ejecutando entrenamiento completo...\\n\")\n",
    "    print(\"‚è∞ Esto puede tardar 30-60 minutos...\\n\")\n",
    "    \n",
    "    trainer.run()\n",
    "    \n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚úÖ PASO 6 COMPLETADO: Entrenamiento del Modelo\")\n",
    "    print(\"‚ñë\" * 100 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚ùå PASO 6 FALL√ì: Entrenamiento del Modelo\")\n",
    "    print(\"‚ñë\" * 100)\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-8"
   },
   "source": [
    "## üìä Secci√≥n 8: Visualizaci√≥n de Resultados de Entrenamiento\n",
    "\n",
    "Visualiza las gr√°ficas generadas durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view-training-plots"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GR√ÅFICAS DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Mostrar gr√°fica de accuracy y loss\n",
    "if os.path.exists('./training_results/training_history.png'):\n",
    "    print(\"üìà Accuracy y Loss vs Epochs:\\n\")\n",
    "    display(Image('./training_results/training_history.png'))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontr√≥ training_history.png\")\n",
    "\n",
    "# Mostrar gr√°fica de m√©tricas avanzadas\n",
    "if os.path.exists('./training_results/advanced_metrics.png'):\n",
    "    print(\"\\nüìä M√©tricas Avanzadas (Precision, Recall, AUC):\\n\")\n",
    "    display(Image('./training_results/advanced_metrics.png'))\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è  No se encontr√≥ advanced_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-9"
   },
   "source": [
    "## üî¨ Secci√≥n 9: PASO 7 - Evaluaci√≥n y Exportaci√≥n con MLflow\n",
    "\n",
    "Eval√∫a el modelo en test set:\n",
    "- Matriz de confusi√≥n\n",
    "- M√©tricas completas (Accuracy, Precision, Recall, F1)\n",
    "- Exportaci√≥n del modelo\n",
    "- Registro en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step-7"
   },
   "outputs": [],
   "source": [
    "from evaluate_and_export import ModelEvaluator\n",
    "\n",
    "print(\"\\n\" + \"‚ñì\" * 100)\n",
    "print(\"‚ñì PASO 7: EVALUACI√ìN Y EXPORTACI√ìN CON MLFLOW\")\n",
    "print(\"‚ñì Eval√∫a en test, genera m√©tricas, matriz de confusi√≥n y registra en MLflow\")\n",
    "print(\"‚ñì\" * 100 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Inicializar evaluador\n",
    "    print(\"üî¨ Inicializando ModelEvaluator...\\n\")\n",
    "    evaluator = ModelEvaluator(\n",
    "        model_path='./training_output/best_model.keras',\n",
    "        output_dir='./evaluation_results',\n",
    "        random_seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Ejecutar evaluaci√≥n completa\n",
    "    print(\"üìä Ejecutando evaluaci√≥n y exportaci√≥n completa...\\n\")\n",
    "    evaluator.run()\n",
    "    \n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚úÖ PASO 7 COMPLETADO: Evaluaci√≥n y Exportaci√≥n\")\n",
    "    print(\"‚ñë\" * 100 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"‚ñë\" * 100)\n",
    "    print(\"‚ñë ‚ùå PASO 7 FALL√ì: Evaluaci√≥n y Exportaci√≥n\")\n",
    "    print(\"‚ñë\" * 100)\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-10"
   },
   "source": [
    "## üìä Secci√≥n 10: Visualizaci√≥n de Resultados de Evaluaci√≥n\n",
    "\n",
    "Visualiza matriz de confusi√≥n y m√©tricas finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view-evaluation"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTADOS DE EVALUACI√ìN EN TEST SET\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Mostrar matriz de confusi√≥n\n",
    "if os.path.exists('./evaluation_results/confusion_matrix.png'):\n",
    "    print(\"üìä Matriz de Confusi√≥n:\\n\")\n",
    "    display(Image('./evaluation_results/confusion_matrix.png'))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontr√≥ confusion_matrix.png\")\n",
    "\n",
    "# Mostrar m√©tricas finales\n",
    "if os.path.exists('./evaluation_results/evaluation_results.json'):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìà M√âTRICAS FINALES EN TEST SET\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    with open('./evaluation_results/evaluation_results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    metrics = results['test_metrics']\n",
    "    print(f\"Accuracy:         {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision (macro): {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"Recall (macro):    {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"F1-score (macro):  {metrics['f1_macro']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"üìä M√âTRICAS POR CLASE\")\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    for class_name, class_metrics in results['class_metrics'].items():\n",
    "        print(f\"{class_name:15s}: Precision={class_metrics['precision']:.4f}, \"\n",
    "              f\"Recall={class_metrics['recall']:.4f}, \"\n",
    "              f\"F1={class_metrics['f1_score']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontr√≥ evaluation_results.json\")\n",
    "\n",
    "# Mostrar classification report\n",
    "if os.path.exists('./evaluation_results/classification_report.csv'):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìÑ CLASSIFICATION REPORT\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    report_df = pd.read_csv('./evaluation_results/classification_report.csv', index_col=0)\n",
    "    print(report_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-11"
   },
   "source": [
    "## üéâ Secci√≥n 11: Resumen Final del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-summary"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"‚ñà\" * 100)\n",
    "print(\"‚ñà\" + \" \" * 35 + \"PIPELINE COMPLETADO EXITOSAMENTE\" + \" \" * 32 + \"‚ñà\")\n",
    "print(\"‚ñà\" * 100)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nüìã ESTADO DE PASOS:\")\n",
    "print(\"   ‚úÖ Paso 4: Configuraci√≥n de entrenamiento\")\n",
    "print(\"   ‚úÖ Paso 5: Creaci√≥n del modelo\")\n",
    "print(\"   ‚úÖ Paso 6: Entrenamiento\")\n",
    "print(\"   ‚úÖ Paso 7: Evaluaci√≥n y MLflow\")\n",
    "\n",
    "print(\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(\"   üìÇ training_output/\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ training_config.json       (Configuraci√≥n)\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ best_model.keras           (Mejor modelo)\")\n",
    "print(\"      ‚îî‚îÄ‚îÄ training_history.csv       (Historial)\")\n",
    "print(\"\\n   üìÇ model_output/\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ model_config.json          (Configuraci√≥n del modelo)\")\n",
    "print(\"      ‚îî‚îÄ‚îÄ model_summary.txt          (Resumen)\")\n",
    "print(\"\\n   üìÇ training_results/\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ training_info.json         (Info completa)\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ training_history.png       (Gr√°ficas)\")\n",
    "print(\"      ‚îî‚îÄ‚îÄ advanced_metrics.png       (M√©tricas)\")\n",
    "print(\"\\n   üìÇ evaluation_results/\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ best_model.keras           (Modelo exportado)\")\n",
    "print(\"      ‚îú‚îÄ‚îÄ confusion_matrix.png       (Matriz)\")\n",
    "print(\"      ‚îî‚îÄ‚îÄ classification_report.csv  (Reporte)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"\\n‚úÖ ¬°Entrenamiento completado!\")\n",
    "print(\"\\nüì• Para descargar los resultados:\")\n",
    "print(\"   - Haz clic derecho en los archivos/carpetas en el panel izquierdo\")\n",
    "print(\"   - Selecciona 'Download'\")\n",
    "print(\"\\nüî¨ MLflow:\")\n",
    "print(\"   - Todos los par√°metros, m√©tricas y artefactos registrados\")\n",
    "print(\"   - Experiment: Maize-Disease-Classification\")\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-12"
   },
   "source": [
    "## üì• Secci√≥n 12: Descargar Resultados (Opcional)\n",
    "\n",
    "Descarga todos los resultados a tu m√°quina local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-results"
   },
   "outputs": [],
   "source": [
    "# Crear archivo ZIP con todos los resultados\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_name = f'corn_disease_results_{timestamp}'\n",
    "\n",
    "print(f\"Creando archivo ZIP: {zip_name}.zip...\\n\")\n",
    "\n",
    "# Crear ZIP con todos los directorios de resultados\n",
    "shutil.make_archive(zip_name, 'zip', '.', \n",
    "                   base_dir=None,\n",
    "                   root_dir='.')\n",
    "\n",
    "# Incluir solo carpetas de resultados\n",
    "folders_to_zip = [\n",
    "    'training_output',\n",
    "    'model_output',\n",
    "    'training_results',\n",
    "    'evaluation_results'\n",
    "]\n",
    "\n",
    "# Crear un ZIP m√°s espec√≠fico\n",
    "!zip -r {zip_name}.zip {' '.join(folders_to_zip)} -x \"*.pyc\" \"__pycache__/*\"\n",
    "\n",
    "print(f\"\\n‚úÖ Archivo creado: {zip_name}.zip\")\n",
    "print(f\"\\nüì• Para descargar:\")\n",
    "print(f\"   from google.colab import files\")\n",
    "print(f\"   files.download('{zip_name}.zip')\")\n",
    "\n",
    "# Descarga autom√°tica (descomenta si quieres descarga autom√°tica)\n",
    "# from google.colab import files\n",
    "# files.download(f'{zip_name}.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-13"
   },
   "source": [
    "## üîÑ Secci√≥n 13: Guardar en Google Drive (Opcional)\n",
    "\n",
    "Guarda los resultados directamente en tu Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-to-drive"
   },
   "outputs": [],
   "source": [
    "# Copiar resultados a Google Drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Definir carpeta destino en Drive\n",
    "drive_results_dir = '/content/drive/MyDrive/Corn_Disease_Results'\n",
    "\n",
    "print(f\"Copiando resultados a Google Drive...\\n\")\n",
    "print(f\"Destino: {drive_results_dir}\\n\")\n",
    "\n",
    "# Crear carpeta en Drive si no existe\n",
    "os.makedirs(drive_results_dir, exist_ok=True)\n",
    "\n",
    "# Copiar cada carpeta de resultados\n",
    "folders_to_copy = [\n",
    "    'training_output',\n",
    "    'model_output',\n",
    "    'training_results',\n",
    "    'evaluation_results'\n",
    "]\n",
    "\n",
    "for folder in folders_to_copy:\n",
    "    if os.path.exists(folder):\n",
    "        dest = os.path.join(drive_results_dir, folder)\n",
    "        if os.path.exists(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(folder, dest)\n",
    "        print(f\"‚úÖ Copiado: {folder} ‚Üí {dest}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No encontrado: {folder}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Resultados guardados en Google Drive\")\n",
    "print(f\"   Ubicaci√≥n: {drive_results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}